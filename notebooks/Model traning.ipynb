{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Algerian_forest_fires_dataset_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['month','day','year'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "df['Classes']=np.where(df['Classes'].str.contains('not fire'),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent and dependent feature\n",
    "X=df.drop('FWI',axis=1)\n",
    "y=df['FWI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection based oon corrrelation\n",
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for multicolinaerity\n",
    "plt.figure(figsize=(12,10))\n",
    "corr=X_train.corr()\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for removing highly postive corelation\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresold- DOmain expertise\n",
    "corr_features = correlation(X_train,0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features when correlation is more than 0.85\n",
    "X_train.drop(corr_features,axis=1,inplace=True)\n",
    "\n",
    "X_test.drop(corr_features,axis=1,inplace=True)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling or standrization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot to understand the effect of standerd scaler\n",
    "plt.subplots(figsize = (15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=X_train)\n",
    "plt.title('X_train Before Scaling')\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data=X_train_scaled)\n",
    "plt.title('X_train After Scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liner Regressing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "y_pred=linreg.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train_scaled,y_train)\n",
    "y_pred=lasso.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS VAlidation Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lassocv = LassoCV(cv=5)\n",
    "lassocv.fit(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv.mse_path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lassocv.predict(X_test_scaled)\n",
    "plt.scatter(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rifge regreesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled,y_train)\n",
    "y_pred=ridge.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge cross validation\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgeCV = RidgeCV()\n",
    "ridgeCV.fit(X_train_scaled,y_train)\n",
    "y_pred = ridgeCV.predict(X_test)\n",
    "plt.scatter(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeCV.alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Reggresion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "elasticNet = ElasticNet()\n",
    "elasticNet.fit(X_train_scaled,y_train)\n",
    "y_pred=elasticNet.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticnet cross validation\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "elasticNetCV = ElasticNetCV()\n",
    "elasticNetCV.fit(X_train_scaled,y_train)\n",
    "y_pred = elasticNetCV.predict(X_test)\n",
    "plt.scatter(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('Mean absolute error',mae)\n",
    "print('R2_score',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNetCV.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picklethe machine learning models,preporcessing model standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler,open('scaler.pkl','wb'))\n",
    "pickle.dump(ridge,open('ridge.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
